{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\emanu\\anaconda3\\lib\\site-packages (0.1.10)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (0.0.25)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.28 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (0.1.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (0.1.13)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.28->langchain) (3.5.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\emanu\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1.28->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\emanu\\anaconda3\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from openai) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from openai) (1.10.8)\n",
      "Requirement already satisfied: sniffio in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\emanu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#insert keyl\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m lm \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, openai_api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#insert key\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emanu\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2023.7.22)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32077 sha256=03766d3308af6050f0f4f98ec66bffebdad520456dd0ac613304e01eb55c4ecb\n",
      "  Stored in directory: c:\\users\\emanu\\appdata\\local\\pip\\cache\\wheels\\6e\\42\\3e\\aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [\"serpapi\"]\n",
    "tools = load_tools(tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emanu\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emanu\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for information about ControlNet to answer this question.\n",
      "Action: Search\n",
      "Action Input: \"ControlNet\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mControlNet is a neural network structure to control diffusion models by adding extra conditions. It copys the weights of neural network blocks into a \"locked\" copy and a \"trainable\" copy. The \"trainable\" one learns your condition. The \"locked\" one preserves your model.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information is helpful, but I should search for more sources to confirm this definition.\n",
      "Action: Search\n",
      "Action Input: \"ControlNet definition\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['ControlNet is an open industrial network protocol for industrial automation applications, also known as a fieldbus.', 'ControlNet kgmid: /m/02z9j6h.', 'ControlNet is an open industrial network protocol for industrial automation applications, also known as a fieldbus.', 'ControlNet refers to a group of neural networks refined using Stable Diffusion, which empowers precise artistic and structural control in ...', 'ControlNet is an open industrial network protocol and is managed by “Open DeviceNet Vendors Association” or ODVA. ControlNet is based on a “ ...', 'ControlNet is a family of neural networks fine-tuned on Stable Diffusion that allows us to have more structural and artistic control over image ...', 'ControlNet is a neural network that controls a pretrained image Diffusion model (e.g. Stable Diffusion). Its function is to allow input of a ...', 'https://www.rockwellautomation.com/en-us/products/hardware/allen-bradley/network-security-and-infrastructure/controlnet-networks.html', 'An object is a collection of related services and attributes. Services are procedures an object performs. Attributes are characteristics of.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This definition seems to align with the previous one, but I should also search for examples of ControlNet in use.\n",
      "Action: Search\n",
      "Action Input: \"ControlNet examples\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['ControlNet is a neural network that controls image generation in Stable Diffusion by adding extra conditions. Details can be found in the ...', 'ControlNet refers to a group of neural networks refined using Stable Diffusion, which empowers precise artistic and structural control in ...', 'ControlNet is a new way of conditioning input images and prompts for image generation. It allows us to control the final image generation ...', 'Your guides are very helpful, and very much appreciated! I enjoy your examples and how clearly you explain how things work.', \"I guess Segment Anything lets you not need to manually segment an image? The example images don't seem to be particularly better than what one could generate ...\", 'ControlNet provides a minimal interface allowing users to customize the generation process up to a great extent. With ControlNet, users can ...', 'ControlNet is a flexible tool that allows you to utilize Stable Diffusion using different condition input types. The following are some examples ...', 'This article aims to provide an insightful exploration of ControlNet models, their varied types, and their applications within Stable Diffusion ...', 'Official implementation of Adding Conditional Control to Text-to-Image Diffusion Models. ControlNet is a neural network structure to control diffusion ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m These examples demonstrate the practical applications of ControlNet and confirm its definition. I now know the final answer.\n",
      "Final Answer: ControlNet is a neural network structure used to control diffusion models by adding extra conditions, allowing for more precise artistic and structural control in image generation. It is an open industrial network protocol managed by the ODVA and has various applications in Stable Diffusion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ControlNet is a neural network structure used to control diffusion models by adding extra conditions, allowing for more precise artistic and structural control in image generation. It is an open industrial network protocol managed by the ODVA and has various applications in Stable Diffusion.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is ControlNet?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for information about Stable Diffusion and the ldm environment.\n",
      "Action: Search\n",
      "Action Input: \"Stable Diffusion ldm environment\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Make sure you are in the proper environment by executing the command conda activate ldm . To generate an image, run the following command:', 'Stable Diffusion v1 refers to a specific configuration of the model architecture that uses a downsampling-factor 8 autoencoder with an 860M UNet and CLIP ...', 'A latent text-to-image diffusion model. Contribute to CompVis/stable-diffusion development by creating an account on GitHub ... name: ldm channels: - pytorch - ...', 'The ldm environment we created is essential, and you need to activate it any time you want to use Stable Diffusion. Enter conda activate ldm ...', 'Stable Diffusion v1-4 Model Card. Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text ...', 'The way you create it is by copying the dependencies from the environment.yaml in the main stable diffusion folder into a separate text document ...', 'Stable Diffusion uses a kind of diffusion model (DM), called a latent diffusion model (LDM) developed by the CompVis group at LMU Munich.', 'Set an environment variable so that MPS falls back to the CPU. $ export PYTORCH_ENABLE_MPS_FALLBACK=1. Start generating images! $ python scripts/txt2img ...', 'In short, an LDM is an application of diffusion processes in the latent space instead of pixel space while incorporating the semantic feedback ...', 'The ability to create striking visuals from text descriptions has a magical quality to it and points clearly to a shift in how humans create art ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should read through the observations to understand what the ldm environment is and how it relates to Stable Diffusion.\n",
      "Action: Read through the observations.\n",
      "Action Input: N/A\u001b[0m\n",
      "Observation: Read through the observations. is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the search tool to find more information about Stable Diffusion and the ldm environment.\n",
      "Action: Search\n",
      "Action Input: \"Stable Diffusion ldm environment\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Make sure you are in the proper environment by executing the command conda activate ldm . To generate an image, run the following command:', 'Stable Diffusion v1 refers to a specific configuration of the model architecture that uses a downsampling-factor 8 autoencoder with an 860M UNet and CLIP ...', 'A latent text-to-image diffusion model. Contribute to CompVis/stable-diffusion development by creating an account on GitHub ... name: ldm channels: - pytorch - ...', 'The ldm environment we created is essential, and you need to activate it any time you want to use Stable Diffusion. Enter conda activate ldm ...', 'Stable Diffusion v1-4 Model Card. Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text ...', 'The way you create it is by copying the dependencies from the environment.yaml in the main stable diffusion folder into a separate text document ...', 'Stable Diffusion uses a kind of diffusion model (DM), called a latent diffusion model (LDM) developed by the CompVis group at LMU Munich.', 'Set an environment variable so that MPS falls back to the CPU. $ export PYTORCH_ENABLE_MPS_FALLBACK=1. Start generating images! $ python scripts/txt2img ...', 'In short, an LDM is an application of diffusion processes in the latent space instead of pixel space while incorporating the semantic feedback ...', 'The ability to create striking visuals from text descriptions has a magical quality to it and points clearly to a shift in how humans create art ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The ldm environment in Stable Diffusion is a specific configuration of the model architecture that uses a latent diffusion model (LDM) developed by the CompVis group at LMU Munich. It is essential to activate the ldm environment in order to use Stable Diffusion and generate photo-realistic images from text descriptions.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The ldm environment in Stable Diffusion is a specific configuration of the model architecture that uses a latent diffusion model (LDM) developed by the CompVis group at LMU Munich. It is essential to activate the ldm environment in order to use Stable Diffusion and generate photo-realistic images from text descriptions.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Hwhat is the ldm environment in Stable Diffusion?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
